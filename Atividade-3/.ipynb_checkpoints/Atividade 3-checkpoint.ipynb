{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "from nltk import bigrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução\n",
    "    Esse documento tem como objetivo analisar a expansão de consultas. Para isso serão respondidas algumas questões sobre o assunto. O documento anterior de notícias, disponível em: https://canvas.instructure.com/courses/1310917/files/63843198/download?verifier=wWhCU9ocjBa1uPBQFiNgCPIxgnShIFESev8TlF7p foi utilizado como nossa base de dados. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções auxiliares:\n",
    "    Para responder as perguntas do final do documento foram criadas algumas funções auxiliares que estão descritas a seguir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função para carregar o csv, preencher os espaços NaN e formatar o contéudo que ira ser utilizado\n",
    "def getCSVFormattedAsDF():\n",
    "    df = pd.read_csv(r'/home/rafaelbas/Documentos/RecuperacaoInformacao/Atividade-3/estadao_noticias_eleicao.csv')\n",
    "    df = df.fillna('')\n",
    "    df[\"docs\"] = df[\"titulo\"] + ' ' +  df[\"subTitulo\"] + ' ' + df[\"conteudo\"]\n",
    "    return df\n",
    "\n",
    "#Função para remover as pontuações dos documentos\n",
    "def removePunctuationDocs(docs):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens_lists = docs.apply(lambda text: tokenizer.tokenize(text.lower()))\n",
    "    return tokens_lists\n",
    "\n",
    "#Função para remover stopwords. \n",
    "#stopwords: https://pt.wikipedia.org/wiki/Palavra_vazia\n",
    "def removeStopWords(tokens_lists):\n",
    "    stopword = stopwords.words('portuguese')\n",
    "    filtered_tokens = tokens_lists.apply(lambda tokens: [token for token in tokens if token not in stopword])\n",
    "    return filtered_tokens\n",
    "\n",
    "#Função para gerar os tokens de cada documento do dataframe inicial\n",
    "def getTokens(docs):\n",
    "    tokens = removePunctuationDocs(df[\"docs\"])\n",
    "    filtered_tokens = removeStopWords(tokens)\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Função que retorna a matrix de co-ocorrência. \n",
    "    return matrix:\n",
    "       [{\"palavra1\": [(\"palavrax\", num_ocorrencias), (\"palavray\": num_ocorrencias), ...]\n",
    "        \"palavra2\":  {(palavrak\": num_ocorrencias), (\"word3\": palavraz) ... ]\n",
    "\"\"\"\n",
    "def co_occurrence_matrix(docs_tokens):\n",
    "    docs_bi_grams = docs_tokens.apply(lambda tokens: list(bigrams(tokens)))\n",
    "    collection_big_grams = [bi_gram for doc_big_grams in docs_bi_grams for bi_gram in doc_big_grams]\n",
    "    bigram_freq = nltk.FreqDist(collection_big_grams).most_common(len(collection_big_grams))\n",
    "    matrix = {}\n",
    "    \n",
    "    for bigram in bigram_freq:\n",
    "        postWord = bigram[0][1]\n",
    "        word = bigram[0][0]\n",
    "        count = bigram[1]\n",
    "        co_occurrence_info = (postWord, count)\n",
    "        \n",
    "        if word not in matrix:\n",
    "            matrix[word] = []\n",
    "        matrix[word].append(co_occurrence_info)\n",
    "\n",
    "        \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Função que retorna as 3 maiores incidências de co-ocorrência com a busca em questão\n",
    "def top3Consultas(word, matrix):\n",
    "    if (word in matrix):\n",
    "        co_occurrence_info = matrix[word]\n",
    "        info = [(), (), ()]\n",
    "        for index in range(len(co_occurrence_info)):\n",
    "            info[index] = co_occurrence_info[index]\n",
    "            if (index == 2):\n",
    "                break\n",
    "        return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_tokens(docs_tokens):\n",
    "    dict_token = {}\n",
    "    idx = -1\n",
    "    for doc_token in docs_tokens:\n",
    "        idx += 1\n",
    "        for token in doc_token:\n",
    "            if (token in dict_token):\n",
    "                dict_token[token].add(idx) \n",
    "            else:\n",
    "                dict_token[token] = set()\n",
    "                dict_token[token].add(idx)\n",
    "    return dict_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Retorna o conjunto de tokens da operação pesquisa. # Retorna \n",
    "def search(ipt, tokens):\n",
    "    if (ipt.strip() == \"\"):\n",
    "        return \"Please, inform at least one token\"\n",
    "    \n",
    "    ipt = ipt.split(\" \")\n",
    "    init = ipt[0].lower()\n",
    "    size = len(ipt)\n",
    "    \n",
    "    if (size == 1) :\n",
    "        if init not in tokens:\n",
    "            return \"This token is not present in any news\"\n",
    "        else:\n",
    "            return tokens[init]\n",
    "    else:\n",
    "        result = tokens[init]\n",
    "        command = \"\"\n",
    "        for index in range(1,size):\n",
    "            if (index % 2 == 0):\n",
    "                compare = tokens[ipt[index].lower()]\n",
    "    \n",
    "                if  command == AND:\n",
    "                    result = result & compare\n",
    "                else:\n",
    "                    result = result | compare              \n",
    "            else:\n",
    "                if (ipt[index] != \"AND\" and ipt[index] != \"OR\"):\n",
    "                    return \"Incorrect input. The tokens searched only can be separated by AND-OR\"\n",
    "                elif ipt[index] == \"AND\":\n",
    "                    command = AND\n",
    "                else:\n",
    "                    command = OR\n",
    "    \n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variaveis auxiliares:\n",
    "    A partir das funções auxiliares descritas na seção anterior, criamos algumas váriaveis auxiliares que nos ajudarão a deixar o processo mais rápido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataFrame com os documentos lidos no csv\n",
    "df = getCSVFormattedAsDF()\n",
    "# Váriavel que armazena os tokens de palavras de cada notícia \n",
    "docs_tokens = getTokens(df[\"docs\"])\n",
    "# Váriavel que armazena a matrix de co-ocorrência\n",
    "matrix_co_occurence = co_occurrence_matrix(docs_tokens)\n",
    "# Inicia o dicionario de tokens  \n",
    "tokens = init_tokens(docs_tokens)\n",
    "\n",
    "#enums necessários para o search\n",
    "AND = 1\n",
    "OR=  2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Palavras escolhidas:\n",
    "    Para a realização desta atividade seria necessário a escolha de três palavras inicias para poder fazer a busca. Escolhemos as palavras: petrobrás, cocaína e pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('paulo', 240), ('é', 90), ('graça', 51)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top3Consultas(\"petrobrás\", matrix_co_occurence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('helicóptero', 3), ('pura', 3), ('acrescentou', 2)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top3Consultas(\"cocaína\", matrix_co_occurence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('psdb', 376), ('pmdb', 262), ('governo', 262)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top3Consultas(\"pt\", matrix_co_occurence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Como visto, os resultados foram:\n",
    "[('paulo', 240), ('é', 90), ('graça', 51)]\n",
    "[('helicóptero', 3), ('pura', 3), ('acrescentou', 2)]\n",
    "[('psdb', 376), ('pmdb', 262), ('governo', 262)]\n",
    "\n",
    "Ou seja, para a busca petrobrás, paulo foi a co-ocorrência mais encontrada. Para cocaína, temos helicóptero. E por último, para pt, temos psdb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Perguntas\n",
    "## Quais os termos retornados para a expansão de cada consulta?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top3Consultas(\"petrobrás\", matrix_co_occurence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top3Consultas(\"petrobrás\", matrix_co_occurence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top3Consultas(\"petrobrás\", matrix_co_occurence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como visto, os resultados foram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[('paulo', 240), ('é', 90), ('graça', 51)]\n",
    "[('helicóptero', 3), ('pura', 3), ('acrescentou', 2)]\n",
    "[('psdb', 376), ('pmdb', 262), ('governo', 262)]\n",
    "\n",
    "Ou seja, para a busca petrobrás, paulo foi a co-ocorrência mais encontrada. Para cocaína, temos helicóptero. E por último, para pt, temos psdb."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
