{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "from nltk import bigrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução\n",
    "    Esse documento tem como objetivo analisar a expansão de consultas. Para isso serão respondidas algumas questões sobre o assunto. O documento anterior de notícias, disponível em: https://canvas.instructure.com/courses/1310917/files/63843198/download?verifier=wWhCU9ocjBa1uPBQFiNgCPIxgnShIFESev8TlF7p foi utilizado como nossa base de dados. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções auxiliares:\n",
    "    Para responder as perguntas do final do documento foram criadas algumas funções auxiliares que estão descritas a seguir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função para carregar o csv, preencher os espaços NaN e formatar o contéudo que ira ser utilizado\n",
    "def getCSVFormattedAsDF():\n",
    "    df = pd.read_csv(r'estadao_noticias_eleicao.csv')\n",
    "    df = df.fillna('')\n",
    "    df[\"docs\"] = df[\"titulo\"] + ' ' +  df[\"subTitulo\"] + ' ' + df[\"conteudo\"]\n",
    "    return df\n",
    "\n",
    "#Função para remover as pontuações dos documentos\n",
    "def removePunctuationDocs(docs):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens_lists = docs.apply(lambda text: tokenizer.tokenize(text.lower()))\n",
    "    return tokens_lists\n",
    "\n",
    "#Função para remover stopwords. \n",
    "#stopwords: https://pt.wikipedia.org/wiki/Palavra_vazia\n",
    "def removeStopWords(tokens_lists):\n",
    "    stopword = stopwords.words('portuguese')\n",
    "    filtered_tokens = tokens_lists.apply(lambda tokens: [token for token in tokens if token not in stopword])\n",
    "    return filtered_tokens\n",
    "\n",
    "#Função para gerar os tokens de cada documento do dataframe inicial\n",
    "def getTokens(docs):\n",
    "    tokens = removePunctuationDocs(df[\"docs\"])\n",
    "    filtered_tokens = removeStopWords(tokens)\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Função que retorna a matrix de co-ocorrência. \n",
    "    return matrix:\n",
    "       [{\"palavra1\": [(\"palavrax\", num_ocorrencias), (\"palavray\": num_ocorrencias), ...]\n",
    "        \"palavra2\":  {(palavrak\": num_ocorrencias), (\"word3\": palavraz) ... ]\n",
    "\"\"\"\n",
    "def co_occurrence_matrix(docs_tokens):\n",
    "    docs_bi_grams = docs_tokens.apply(lambda tokens: list(bigrams(tokens)))\n",
    "    collection_big_grams = [bi_gram for doc_big_grams in docs_bi_grams for bi_gram in doc_big_grams]\n",
    "    bigram_freq = nltk.FreqDist(collection_big_grams).most_common(len(collection_big_grams))\n",
    "    matrix = {}\n",
    "    \n",
    "    for bigram in bigram_freq:\n",
    "        postWord = bigram[0][1]\n",
    "        word = bigram[0][0]\n",
    "        count = bigram[1]\n",
    "        co_occurrence_info = (postWord, count)\n",
    "        \n",
    "        if word not in matrix:\n",
    "            matrix[word] = []\n",
    "        matrix[word].append(co_occurrence_info)\n",
    "\n",
    "        \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função que retorna as 3 maiores incidências de co-ocorrência com a busca em questão\n",
    "def top3Consultas(word, matrix):\n",
    "    if (word in matrix):\n",
    "        co_occurrence_info = matrix[word]\n",
    "        info = [(), (), ()]\n",
    "        for index in range(len(co_occurrence_info)):\n",
    "            info[index] = co_occurrence_info[index]\n",
    "            if (index == 2):\n",
    "                break\n",
    "        return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inicia o indice invertido\n",
    "def init_tokens(docs_tokens):\n",
    "    dict_token = {}\n",
    "    idx = -1\n",
    "    for doc_token in docs_tokens:\n",
    "        idx += 1\n",
    "        for token in doc_token:\n",
    "            if (token in dict_token):\n",
    "                dict_token[token].add(idx) \n",
    "            else:\n",
    "                dict_token[token] = set()\n",
    "                dict_token[token].add(idx)\n",
    "    return dict_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retorna o conjunto de tokens da operação pesquisa. # Retorna \n",
    "def search(ipt, tokens):\n",
    "    if (ipt.strip() == \"\"):\n",
    "        return \"Please, inform at least one token\"\n",
    "    \n",
    "    ipt = ipt.split(\" \")\n",
    "    init = ipt[0].lower()\n",
    "    size = len(ipt)\n",
    "    \n",
    "    if (size == 1) :\n",
    "        if init not in tokens:\n",
    "            return \"This token is not present in any news\"\n",
    "        else:\n",
    "            return tokens[init]\n",
    "    else:\n",
    "        result = tokens[init]\n",
    "        command = \"\"\n",
    "        for index in range(1,size):\n",
    "            if (index % 2 == 0):\n",
    "                compare = tokens[ipt[index].lower()]\n",
    "    \n",
    "                if  command == AND:\n",
    "                    result = result & compare\n",
    "                else:\n",
    "                    result = result | compare              \n",
    "            else:\n",
    "                if (ipt[index] != \"AND\" and ipt[index] != \"OR\"):\n",
    "                    return \"Incorrect input. The tokens searched only can be separated by AND-OR\"\n",
    "                elif ipt[index] == \"AND\":\n",
    "                    command = AND\n",
    "                else:\n",
    "                    command = OR\n",
    "    \n",
    "        return set(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variaveis auxiliares:\n",
    "    A partir das funções auxiliares descritas na seção anterior, criamos algumas váriaveis auxiliares que nos ajudarão a deixar o processo mais rápido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataFrame com os documentos lidos no csv\n",
    "df = getCSVFormattedAsDF()\n",
    "# Váriavel que armazena os tokens de palavras de cada notícia \n",
    "docs_tokens = getTokens(df[\"docs\"])\n",
    "# Váriavel que armazena a matrix de co-ocorrência\n",
    "matrix_co_occurence = co_occurrence_matrix(docs_tokens)\n",
    "\n",
    "#constantes necessários para o search\n",
    "AND = 1\n",
    "OR=  2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenização necessário para o search\n",
    "tokens = init_tokens(docs_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Palavras escolhidas:\n",
    "        Para a realização desta atividade seria necessário a escolha de três palavras inicias para poder fazer a busca. Escolhemos as palavras: petrobrás, lula e pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Perguntas\n",
    "## Quais os termos retornados para a expansão de cada consulta?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('paulo', 240), ('é', 90), ('graça', 51)]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top3Consultas(\"petrobrás\", matrix_co_occurence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('silva', 1028), ('dilma', 198), ('disse', 106)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top3Consultas(\"lula\", matrix_co_occurence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('psdb', 376), ('pmdb', 262), ('governo', 262)]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top3Consultas(\"pt\", matrix_co_occurence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como visto, os resultados foram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[('paulo', 240), ('é', 90), ('graça', 51)]\n",
    "[('silva', 1028), ('dilma', 198), ('disse', 106)]\n",
    "[('psdb', 376), ('pmdb', 262), ('governo', 262)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou seja, para a busca petrobrás, paulo foi a co-ocorrência mais encontrada. Para lula, temos silva. \n",
    "E por último, para pt, temos psdb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Você acha que esses termos são de fato relacionados com a consulta original? Justifique.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  <div style=\"text-align: justify;\">\n",
    "       <p> &emsp; De uma certa forma? Sim. Na primeira pesquisa temos petrobrás. Os termos encontrados foram:\n",
    "    \"Paulo\", \"Graça\" e \"é\". Devido a base de dados, acredita-se que Paulo e Graça devam se referir, respectivamente, a Paulo Roberto Costa e Graça Foster, ex-diretores da petrobrás. A palavra \"é\" indica que a função removeStopWords deve ser melhorada.\n",
    "       </p>\n",
    "    <p>&emsp;\n",
    "    Na segunda pesquisa(\"lula\"), obtivemos como resultado: silva, dilma e disse. O que também mostra relação, já que silva faz parte do nome do ex-presidente e dilma está diretamente ligada com o nome de lula.\n",
    "    </p>\n",
    "    <p>&emsp;\n",
    "    Na terceira pesquisa(\"pt\") encontramos: \"psdb\", \"pmdb\", \"governo\", o que mostra uma relação, já que psdb e pmdb são partidos politicos e o pt governou o país por mais de 14 anos. \n",
    "    </p>\n",
    "</div>\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare os documentos retornados para a consulta original com a consulta expandida. Quais resultados você acha que melhor capturam a necessidade de informação do usuário? Por que? A expansão de consultas é mais adequada para melhorar o recall ou o precision? Por que?\n",
    "\n",
    "Ps: Responderei as duas em um texo só"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(search(\"petrobrás\", tokens))\n",
    "len(search([\"petrobrás\", \"paulo\", \"é\", \"graça\"], tokens))\n",
    "len(search(\"lula\", tokens))\n",
    "len(search([\"lula\", \"silva\", \"dilma\", \"disse\"], tokens))\n",
    "len(search(\"pt\", tokens))\n",
    "len(search([\"pt\", \"psdb\", \"pmdb\", \"governo\"], tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width:100%\">\n",
    "  <tr>\n",
    "    <th>Termo</th>\n",
    "    <th>Busca Expandida</th> \n",
    "    <th>Num Docs</th>\n",
    "    <th>Num Docs Busca Expandida</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>petrobrás</td>\n",
    "    <td>petrobrás, paulo, é, graça</td> \n",
    "    <td>1043</td>\n",
    "    <td>7200</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>lula</td>\n",
    "    <td>lula, silva, dilma, disse</td> \n",
    "    <td>1893</td>\n",
    "    <td>6405</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>pt</td>\n",
    "    <td>pt, psdb, pmdb, governo</td> \n",
    "    <td>4018</td>\n",
    "    <td>6509</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:justify\"> Acho que a captura da necessidade depende do contexto. Nota-se que a busca expansiva coleta mais documentos do que a original. Por um ponto de vista pode ser bom, já que sua busca vai retornar mais documentos que podem se relacionar com sua pesquisa, já que sua busca contém termos que se relacionam com o termo original. Ou seja, a pesquisa vai melhorar o <b>recall</b>. Contudo, se eu quero <b>precisão</b>, a consulta expandida pode não retornar os resultados mais precisos. Por exemplo, na busca do termo petrobrás, temos o termo \"é\" em nossa consulta expandida. O termo \"é\" é um termo comum na lingua portuguesa, que provavelmente deve ter aparecido em vários documentos que podem não ter uma relação muito direta com o termo original. O mesmo exemplo vale para o termo \"disse\" na busca por \"lula\". </div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
